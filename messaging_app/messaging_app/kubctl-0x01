#!/bin/bash

# kubctl-0x01 - Kubernetes Scaling and Load Testing Script
# Objective: Learn how to scale applications in Kubernetes

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Configuration
DEPLOYMENT_NAME="messaging-app"
SERVICE_NAME="messaging-app-service"
TARGET_REPLICAS=3
LOAD_TEST_DURATION=30
LOAD_TEST_CONNECTIONS=10
LOAD_TEST_THREADS=2

# Function to print colored output
print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_header() {
    echo -e "${PURPLE}==========================================${NC}"
    echo -e "${PURPLE}    $1${NC}"
    echo -e "${PURPLE}==========================================${NC}"
    echo ""
}

print_subheader() {
    echo -e "${CYAN}--- $1 ---${NC}"
}

# Function to check if a command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to check prerequisites
check_prerequisites() {
    print_header "Checking Prerequisites"
    
    # Check kubectl
    if ! command_exists kubectl; then
        print_error "kubectl is not installed!"
        exit 1
    fi
    print_success "kubectl found: $(kubectl version --client --short)"
    
    # Check wrk
    if ! command_exists wrk; then
        print_warning "wrk is not installed. Installing wrk..."
        if [[ "$OSTYPE" == "darwin"* ]]; then
            brew install wrk
        elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
            sudo apt-get update && sudo apt-get install -y wrk
        else
            print_error "Please install wrk manually for your OS"
            exit 1
        fi
    fi
    print_success "wrk found: $(wrk --version | head -n1)"
    
    # Check if cluster is accessible
    if ! kubectl cluster-info &> /dev/null; then
        print_error "Cannot connect to Kubernetes cluster!"
        exit 1
    fi
    print_success "Connected to Kubernetes cluster"
}

# Function to get current deployment status
get_current_status() {
    print_header "Current Deployment Status"
    
    print_subheader "Current Replicas"
    kubectl get deployment $DEPLOYMENT_NAME -o jsonpath='{.spec.replicas}' 2>/dev/null || echo "0"
    
    print_subheader "Current Pods"
    kubectl get pods -l app=$DEPLOYMENT_NAME
    
    print_subheader "Current Services"
    kubectl get services -l app=$DEPLOYMENT_NAME
    
    print_subheader "Current Resource Usage"
    if command_exists kubectl-top; then
        kubectl top pods -l app=$DEPLOYMENT_NAME
    else
        print_warning "kubectl top not available. Install metrics-server for resource monitoring."
    fi
}

# Function to scale the deployment
scale_deployment() {
    print_header "Scaling Deployment"
    
    print_status "Scaling $DEPLOYMENT_NAME to $TARGET_REPLICAS replicas..."
    kubectl scale deployment $DEPLOYMENT_NAME --replicas=$TARGET_REPLICAS
    
    if [ $? -eq 0 ]; then
        print_success "Deployment scaled successfully to $TARGET_REPLICAS replicas"
    else
        print_error "Failed to scale deployment"
        exit 1
    fi
}

# Function to wait for scaling to complete
wait_for_scaling() {
    print_header "Waiting for Scaling to Complete"
    
    print_status "Waiting for all pods to be ready..."
    kubectl wait --for=condition=available --timeout=300s deployment/$DEPLOYMENT_NAME
    
    print_status "Waiting for all pods to be running..."
    kubectl wait --for=condition=ready --timeout=300s pods -l app=$DEPLOYMENT_NAME
    
    print_success "All pods are ready and running!"
}

# Function to verify scaling
verify_scaling() {
    print_header "Verifying Scaling"
    
    print_subheader "Deployment Status"
    kubectl get deployment $DEPLOYMENT_NAME
    
    print_subheader "Pod Status"
    kubectl get pods -l app=$DEPLOYMENT_NAME
    
    print_subheader "Pod Details"
    kubectl describe pods -l app=$DEPLOYMENT_NAME
    
    # Count running pods
    RUNNING_PODS=$(kubectl get pods -l app=$DEPLOYMENT_NAME --field-selector=status.phase=Running -o name | wc -l)
    print_status "Running pods: $RUNNING_PODS"
    
    if [ "$RUNNING_PODS" -eq "$TARGET_REPLICAS" ]; then
        print_success "Scaling verified! All $TARGET_REPLICAS pods are running."
    else
        print_error "Scaling verification failed! Expected $TARGET_REPLICAS pods, got $RUNNING_PODS"
        exit 1
    fi
}

# Function to get service endpoint for load testing
get_service_endpoint() {
    print_header "Getting Service Endpoint"
    
    # Check if we're using minikube
    if command_exists minikube && minikube status &> /dev/null; then
        print_status "Using minikube tunnel for external access..."
        # Start minikube tunnel in background
        minikube tunnel &
        TUNNEL_PID=$!
        sleep 10
        
        # Get the service URL
        SERVICE_URL=$(minikube service $SERVICE_NAME --url)
        print_success "Service accessible at: $SERVICE_URL"
        echo $SERVICE_URL > /tmp/service_url.txt
        echo $TUNNEL_PID > /tmp/tunnel_pid.txt
    else
        # For other clusters, try to get the service IP
        SERVICE_IP=$(kubectl get service $SERVICE_NAME -o jsonpath='{.spec.clusterIP}')
        SERVICE_PORT=$(kubectl get service $SERVICE_NAME -o jsonpath='{.spec.ports[0].port}')
        SERVICE_URL="http://$SERVICE_IP:$SERVICE_PORT"
        print_success "Service accessible at: $SERVICE_URL"
        echo $SERVICE_URL > /tmp/service_url.txt
    fi
}

# Function to perform load testing
perform_load_testing() {
    print_header "Performing Load Testing"
    
    # Get service URL
    if [ -f /tmp/service_url.txt ]; then
        SERVICE_URL=$(cat /tmp/service_url.txt)
    else
        print_error "Service URL not found. Cannot perform load testing."
        return 1
    fi
    
    print_status "Starting load test with wrk..."
    print_status "Duration: ${LOAD_TEST_DURATION}s"
    print_status "Connections: ${LOAD_TEST_CONNECTIONS}"
    print_status "Threads: ${LOAD_TEST_THREADS}"
    print_status "Target: $SERVICE_URL/health/"
    
    # Create load test results directory
    mkdir -p load_test_results
    
    # Run wrk load test
    wrk -t${LOAD_TEST_THREADS} -c${LOAD_TEST_CONNECTIONS} -d${LOAD_TEST_DURATION} \
        --latency --timeout 10s "$SERVICE_URL/health/" > load_test_results/wrk_results.txt
    
    if [ $? -eq 0 ]; then
        print_success "Load testing completed successfully!"
        
        print_subheader "Load Test Results"
        cat load_test_results/wrk_results.txt
        
        # Save results with timestamp
        TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
        cp load_test_results/wrk_results.txt "load_test_results/wrk_results_${TIMESTAMP}.txt"
        print_status "Results saved to: load_test_results/wrk_results_${TIMESTAMP}.txt"
    else
        print_error "Load testing failed!"
        return 1
    fi
}

# Function to monitor resource usage
monitor_resources() {
    print_header "Monitoring Resource Usage"
    
    print_subheader "Resource Usage Before Load Test"
    if command_exists kubectl-top; then
        kubectl top pods -l app=$DEPLOYMENT_NAME
    else
        print_warning "kubectl top not available. Install metrics-server for resource monitoring."
        print_status "Installing metrics-server..."
        
        # Try to install metrics-server
        kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
        
        # Wait for metrics-server to be ready
        print_status "Waiting for metrics-server to be ready..."
        kubectl wait --for=condition=available --timeout=300s deployment/metrics-server -n kube-system
        
        print_status "Retrying resource monitoring..."
        sleep 10
        kubectl top pods -l app=$DEPLOYMENT_NAME
    fi
    
    print_subheader "Pod Resource Requests and Limits"
    kubectl get pods -l app=$DEPLOYMENT_NAME -o custom-columns="NAME:.metadata.name,CPU_REQUEST:.spec.containers[0].resources.requests.cpu,CPU_LIMIT:.spec.containers[0].resources.limits.cpu,MEMORY_REQUEST:.spec.containers[0].resources.requests.memory,MEMORY_LIMIT:.spec.containers[0].resources.limits.memory"
    
    print_subheader "Node Resource Usage"
    kubectl top nodes
}

# Function to show detailed pod information
show_pod_details() {
    print_header "Detailed Pod Information"
    
    PODS=$(kubectl get pods -l app=$DEPLOYMENT_NAME -o jsonpath='{.items[*].metadata.name}')
    
    for pod in $PODS; do
        print_subheader "Pod: $pod"
        kubectl describe pod $pod | grep -E "(Status:|Ready:|Containers:|Events:)"
        echo ""
    done
}

# Function to show logs from all pods
show_pod_logs() {
    print_header "Pod Logs"
    
    PODS=$(kubectl get pods -l app=$DEPLOYMENT_NAME -o jsonpath='{.items[*].metadata.name}')
    
    for pod in $PODS; do
        print_subheader "Logs from: $pod"
        echo "----------------------------------------"
        kubectl logs $pod --tail=10
        echo ""
    done
}

# Function to cleanup
cleanup() {
    print_header "Cleanup"
    
    # Stop minikube tunnel if running
    if [ -f /tmp/tunnel_pid.txt ]; then
        TUNNEL_PID=$(cat /tmp/tunnel_pid.txt)
        if kill -0 $TUNNEL_PID 2>/dev/null; then
            print_status "Stopping minikube tunnel..."
            kill $TUNNEL_PID
            rm -f /tmp/tunnel_pid.txt
        fi
        rm -f /tmp/service_url.txt
    fi
    
    print_success "Cleanup completed!"
}

# Function to show help
show_help() {
    echo "kubctl-0x01 - Kubernetes Scaling and Load Testing Script"
    echo ""
    echo "Usage: $0 [COMMAND]"
    echo ""
    echo "Commands:"
    echo "  (no args)  Full scaling and load testing"
    echo "  scale       Scale deployment to $TARGET_REPLICAS replicas"
    echo "  verify      Verify scaling status"
    echo "  loadtest    Perform load testing with wrk"
    echo "  monitor     Monitor resource usage"
    echo "  status      Show current deployment status"
    echo "  logs        Show pod logs"
    echo "  cleanup     Cleanup temporary resources"
    echo "  help        Show this help message"
    echo ""
    echo "Examples:"
    echo "  $0           # Run full scaling and load testing"
    echo "  $0 scale     # Scale deployment only"
    echo "  $0 loadtest  # Run load testing only"
}

# Main execution
main() {
    print_header "Kubernetes Scaling and Load Testing"
    
    # Check prerequisites
    check_prerequisites
    
    # Get current status
    get_current_status
    
    # Scale deployment
    scale_deployment
    
    # Wait for scaling
    wait_for_scaling
    
    # Verify scaling
    verify_scaling
    
    # Monitor resources before load test
    monitor_resources
    
    # Get service endpoint
    get_service_endpoint
    
    # Perform load testing
    perform_load_testing
    
    # Monitor resources after load test
    print_subheader "Resource Usage After Load Test"
    if command_exists kubectl-top; then
        kubectl top pods -l app=$DEPLOYMENT_NAME
    fi
    
    # Show final status
    print_header "Final Status"
    show_pod_details
    show_pod_logs
    
    print_success "Scaling and load testing completed successfully!"
    print_status "Your Django app is now running with $TARGET_REPLICAS replicas"
    print_status "Load test results saved in: load_test_results/"
    
    # Cleanup
    cleanup
}

# Handle command line arguments
case "${1:-}" in
    "scale")
        check_prerequisites
        scale_deployment
        wait_for_scaling
        verify_scaling
        ;;
    "verify")
        check_prerequisites
        verify_scaling
        ;;
    "loadtest")
        check_prerequisites
        get_service_endpoint
        perform_load_testing
        cleanup
        ;;
    "monitor")
        check_prerequisites
        monitor_resources
        ;;
    "status")
        check_prerequisites
        get_current_status
        ;;
    "logs")
        check_prerequisites
        show_pod_logs
        ;;
    "cleanup")
        cleanup
        ;;
    "help"|"-h"|"--help")
        show_help
        ;;
    "")
        main
        ;;
    *)
        print_error "Unknown command: $1"
        show_help
        exit 1
        ;;
esac
